---
title: "Automated Diagnosis of Otitis Media in Temporal Bone Computed Tomography Images Using Deep Learning"
collection: publications
category: processing
permalink: /publication/13
excerpt: 'Yong Tang, Siyi Wang, Zhitao Cheng, Yanling Leng, Yuhang Liu, Tingfang Wu, Jing Fei, Leiji Li. Automated Diagnosis of Otitis Media in Temporal Bone Computed Tomography Images Using Deep Learning. Submitted to Ear and hearing, 2024. Objectives: To develop and evaluate a deep learning (DL) framework for the automated diagnosis of otitis media (OM) using temporal bone computed tomography (TBCT) images. Design: In this diagnostic study, we retrospectively collected 2011 TBCT images of 1200 patients treated between September 2018 to June 2024 in The Affiliated Hospital of Southwest Medical University. Experts manually delineated the regions of interest (ROI) for middle ears (MEs). The statuses of visible MEs were labeled as normal middle ear (NME), otitis media with effusion (OME), or chronic otitis media (COM) with or without cholesteatoma, according to the clinical diagnosis records. The final dataset contained 400 NME, 214 OME, and 586 COM patients. There were 402 ME regions for NME, 998 ME regions for OME, and 619 ME regions for COM cases in TBCT images, respectively. A DL framework was developed to detect the MEs in TBCT images and determine the OM status. Of these images, 1605 were used for training and validation, and 406 were used for model evaluation. Five-fold cross-validation was utilized for training and selecting the models. The performance of the DL framework was evaluated by metrics including the mean average precision (mAP), area under the receiver operating characteristic curve (AUC), accuracy (ACC), F1-score, sensitivity, and specificity. The evaluation strategy employed for the classification of three categories is one vs rest (OvR), which means we compute the AUC, sensitivity, and specificity for each category against the remaining ones respectively, followed by averaging these three results to obtain the outcome. Furthermore, the balanced test dataset which includes 406 images was used to evaluate the effectiveness of model-assisted diagnosis for both senior and junior clinicians. Results: The DL model achieved an average mAP of 0.9136 for the detection of MEs. Based on the detection, the model, which has a detection ratio of 98.53% (1.47% MEs were not detected), obtained an AUC of 0.9951 (95% CI, 0.9903 â€“ 0.9982), an ACC of 0.9238, an F1-score of 0.9392, a sensitivity of 0.9395, and a specificity of 0.9700, for the classification of NME, OME, and COM. In comparison experiments, with the assistance of the DL, the diagnostic accuracies improved from 81.53% to 93.60% (junior clinician) and 87.93% to 95.57% (senior clinician), respectively. Conclusions: The findings suggested that the DL model could accurately identify MEs in TBCT images and classify NME, OME, and COM with satisfying accuracy. DL could also effectively assist clinicians in TBCT interpretation for OM diagnosis.'
date: 2024-12-30
venue: 'Ear and hearing'
---
